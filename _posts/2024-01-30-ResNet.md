---
layout: single
title: "[Paper Review] Deep Residual Learning for Image Recognition"
categories: [AI, Paper Review]
tag: []
typora-root-url: ../
use_math: true
---

<font color=gray>ResNet을 제시하여 이미지 인식에 큰 영향을 끼친 'Deep Residual Learning for Image Recognition' 논문 리뷰입니다.</font> <br>

> 논문 list는 이 [repo](https://github.com/SEUNGW00LEE/paper_review)에 정리되어있습니다.

# [Deep Residual Learning for Image Recognition](https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf)

---

**K. He, X. Zhang, S. Ren and J. Sun, "Deep Residual Learning for Image Recognition," *2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)*, Las Vegas, NV, USA, 2016, pp.**

---



## **0. Overview**

**지금까지의 어떤 문제가 있었나?**

- depth가 깊이가 모델의 성능에 큰 영향을 끼치는 것은 자명하지만, 이전의 framework는 network가 깊어질수록 훈련시키기 어려운 문제를 가진다. (오버피팅, gradient 소멸, 연산량 증가)

**해당 논문에서는 어떻게 해결할 수 있나?**

- 함수를 새로 만드는 방법 대신에 residual function(잔차 함수)을 통해 잔차 함수를 learning에 사용하는 것으로 layer를 재구성한다. 
- Residual이란 결과의 오류라고 할 수 있는데, 지금까지 평가의 기준으로 삼았지만 이를 이용해 학습하였다.
- 이를 통해 이전의 모델보다 훨씬 깊은 layer(152 layer)를 가질 수 있다.

**해당 연구를 통한 성과는 무엇이 있나?**

1. ResNet은 VGG net보다 8배 깊은 152 layer를 가지지만 복잡하지 않고 최적화시키기 쉽고, 깊은 깊이에서도 정확도를 얻을 수 있다.
2. 여기에 앙상블 기법을 적용하여 3.57% error를 가진다.
3. Image classification 뿐만 아니라, object detection등 전분야에서 탁월한 성능을 보인다.



## **1. Introduction**



지금까지의 연구를 통해 깊은 네트워크는 중요한 요소이며, 좋은 결과를 위해서는 많은 layer가 필요하다는 것을 알 수 있다.

필자는 아래와 같은 질문을 남긴다.

> Is learning better networks as easy as stacking more layers?

more layer에는 다음과 같은 문제를 야기한다.

- Vanishing/exploding gradient

위의 문제는 normalized initialization, intermediate normalization layer의 방법을 통해 개선하여 수십개의 layer까지는 해결하였다.

그러나 더 깊어질수록, `degradation`문제가 발생한다.

이 `degradation`의 문제는 오버피팅때문이 아니라 layer가 많아질 수록 생기는 문제이다. 

![image-20240130205449608](/images/2024-01-30-ResNet/image-20240130205449608.png)

위의 그래프가 그 예시인데, 그림에서 볼 수 있듯이 layer가 더 깊은 layer가 training error, test error 모두 높은 것을 확인할 수 있다.

layer가 깊어질수록 훈련을 잘 못한다고 필자는 주장한다.









